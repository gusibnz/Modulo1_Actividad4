{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modulo1_Actividad4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install gplearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7FMbOpuU6In",
        "outputId": "6f4270e5-3694-4946-96ff-93870b13208d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gplearn\n",
            "  Downloading gplearn-0.4.1-py3-none-any.whl (41 kB)\n",
            "\u001b[?25l\r\u001b[K     |████████                        | 10 kB 19.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 20 kB 16.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 30 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 40 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 41 kB 222 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from gplearn) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from gplearn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->gplearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->gplearn) (1.21.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->gplearn) (3.1.0)\n",
            "Installing collected packages: gplearn\n",
            "Successfully installed gplearn-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CG9YdNwRUHnQ"
      },
      "outputs": [],
      "source": [
        "from gplearn.genetic import SymbolicTransformer\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rng = check_random_state(0)\n",
        "boston = load_boston()\n",
        "perm = rng.permutation(boston.target.size)\n",
        "boston.data = boston.data[perm]\n",
        "boston.target = boston.target[perm]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaaqAT0OVADO",
        "outputId": "4c8cfbb3-4eb3-42f7-f54c-d70982666aae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "est = Ridge()\n",
        "est.fit(boston.data[:300, :], boston.target[:300])\n",
        "print(est.score(boston.data[300:, :], boston.target[300:]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1N-CryDVPEN",
        "outputId": "e1a2bc68-f3ca-4800-fe3e-38bd021c3087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.759319453049884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function_set = ['add', 'sub', 'mul', 'div',\n",
        "                'sqrt', 'log', 'abs', 'neg', 'inv',\n",
        "                'max', 'min']\n",
        "gp = SymbolicTransformer(generations=20, population_size=2000,\n",
        "                         hall_of_fame=100, n_components=10,\n",
        "                         function_set=function_set,\n",
        "                         parsimony_coefficient=0.0005,\n",
        "                         max_samples=0.9, verbose=1,\n",
        "                         random_state=0, n_jobs=3)\n",
        "gp.fit(boston.data[:300, :], boston.target[:300])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFf0Lb6-WU59",
        "outputId": "066dcfa8-2b9b-4e96-aecd-430e15f4ed35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    11.04         0.339876        6         0.822502         0.675124      1.16m\n",
            "   1     6.91         0.593562        7         0.836993         0.602468      1.18m\n",
            "   2     5.07         0.730093        8          0.84063         0.704017      1.26m\n",
            "   3     5.22         0.735525        5         0.847019         0.628351      1.20m\n",
            "   4     6.24         0.734679       10         0.856612         0.565138      1.12m\n",
            "   5     8.23         0.721433       18          0.85677         0.728095      1.10m\n",
            "   6    10.20         0.717937       14         0.875233         0.619693      1.09m\n",
            "   7    11.84         0.720667       14         0.875927         0.609363     59.55s\n",
            "   8    12.56         0.733019       27         0.881705         0.390121     56.20s\n",
            "   9    13.61          0.73144       16         0.873285         0.598466     53.21s\n",
            "  10    14.81         0.737687       16         0.873915          0.67127     48.19s\n",
            "  11    14.84          0.73787       21         0.874944         0.467722     44.97s\n",
            "  12    15.40         0.740935       22         0.878053         0.534554     39.06s\n",
            "  13    16.83         0.743265       15         0.874735         0.635764     33.53s\n",
            "  14    17.04         0.741628       13         0.884417         0.493354     31.68s\n",
            "  15    17.02         0.744034       26         0.892236         0.647918     23.03s\n",
            "  16    18.23         0.738467       43         0.879153         0.377872     17.12s\n",
            "  17    18.09         0.722973       16         0.889763         0.508006     11.87s\n",
            "  18    19.58          0.70793       27         0.889402         0.639016      5.88s\n",
            "  19    21.69         0.697116       24         0.888272          0.56025      0.00s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SymbolicTransformer(function_set=['add', 'sub', 'mul', 'div', 'sqrt', 'log',\n",
              "                                  'abs', 'neg', 'inv', 'max', 'min'],\n",
              "                    max_samples=0.9, n_jobs=3, parsimony_coefficient=0.0005,\n",
              "                    population_size=2000, random_state=0, verbose=1)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGDQz7Y-y8l5",
        "outputId": "a33b6fd0-c96b-4e46-a405-502874cc3163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SymbolicTransformer(function_set=['add', 'sub', 'mul', 'div', 'sqrt', 'log',\n",
              "                                  'abs', 'neg', 'inv', 'max', 'min'],\n",
              "                    max_samples=0.9, n_jobs=3, parsimony_coefficient=0.0005,\n",
              "                    population_size=2000, random_state=0, verbose=1)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gp_features = gp.transform(boston.data)\n",
        "new_boston = np.hstack((boston.data, gp_features))"
      ],
      "metadata": {
        "id": "gmdDe9AfWwIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "est = Ridge()\n",
        "est.fit(new_boston[:300, :], boston.target[:300])\n",
        "print(est.score(new_boston[300:, :], boston.target[300:]))"
      ],
      "metadata": {
        "id": "35iMQwfLW4d8",
        "outputId": "c1e912e9-c595-4784-a695-63bfbcc4fc05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8418372105182054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Symbolic Transformation** genera distintos ajustes por medio de un algoritmo genético, lo que hace que nuestras opciones de ajuste vengan de un proceso de \"evolución\" el cual podemos controlar con los distintos parametros, como el número de generaciones, los individuos que se copian a las siguientes generaciones, el porcentaje de mutaciones que tenemos, etc... Este proceso permite que los datos tengan una gran variedad de opciones de ajuste para elegir. Nos permite explorar muchas opciones de ajuste en poco tiempo y poder descartar rapidamente aquellas que no son buenos ajustes. Además de que el modificar los parámetros nos permite buscar distintos resultados y encontrar mejores resultados.\n",
        "\n"
      ],
      "metadata": {
        "id": "qSvZL6Wc2N5g"
      }
    }
  ]
}